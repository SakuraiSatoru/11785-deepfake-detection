{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Modal Model\n",
    "Densenet + AudioConv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import OrderedDict\n",
    "\n",
    "import importlib\n",
    "\n",
    "import dataloader\n",
    "from audio_conv2d import AudioConv2d\n",
    "from Densenet import densenet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalSimpleConcatModel(nn.Module):\n",
    "    HIDDEN = [1664+2300, 1664+2300]\n",
    "    def __init__(self):\n",
    "        super(MultiModalSimpleConcatModel, self).__init__()\n",
    "        self.densenet = densenet169(pretrained=True, progress=True, memory_efficient=False)\n",
    "        self.audionet = AudioConv2d()\n",
    "        self.linears = nn.Sequential(nn.Linear(self.HIDDEN[0], self.HIDDEN[1]))\n",
    "        self.scoring = nn.Linear(self.HIDDEN[-1], 2)\n",
    "    \n",
    "    def forward(self, videos, audios):\n",
    "        batch_size = videos.shape[0]\n",
    "        assert(videos.shape == (batch_size, 3, 224, 224) and audios.shape == (batch_size, 5, 50))\n",
    "        video_embed, _ = self.densenet(videos) # (N, C, H, W) -> (N, num_features:1664)\n",
    "        audio_embed = self.audionet(audios) # -> (N, num_features:2300)\n",
    "        concat = torch.cat((video_embed, audio_embed), dim=1) # (N, 1664+2300)\n",
    "        \n",
    "        final_embed = self.linears(concat) # (N, 1664+2300)\n",
    "        classification = self.scoring(final_embed) # (N, 2)\n",
    "        return final_embed, classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    BATCH_SIZE = 64\n",
    "\n",
    "    train_video_dataset = dataloader.get_dataset(dataloader.TRAIN_JSON_PATH, dataloader.SINGLE_FRAME)\n",
    "    train_audio_dataset = dataloader.AudioDataset()\n",
    "    train_loader = dataloader.AVDataLoader(train_video_dataset, train_audio_dataset, batch_size=BATCH_SIZE, shuffle=True, single_frame=True)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def verify_model(train_loader):\n",
    "    model = MultiModalSimpleConcatModel()\n",
    "\n",
    "    for v, a, _, _, l in train_loader:\n",
    "        print('videos shape:', v.shape) # batch_size*3(channel)*224*224\n",
    "        print('audios shape:', a.shape) # batch_size*5*50(channel)\n",
    "        print('labels shape:', l.shape) # batch_size\n",
    "\n",
    "        _, classification = model(v, a)\n",
    "        print(classification.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 733589 images \n",
      "videos type(expect tensor): <class 'torch.Tensor'>\n",
      "videos shape: torch.Size([64, 3, 224, 224])\n",
      "audios shape: torch.Size([64, 5, 50])\n",
      "labels shape: torch.Size([64])\n",
      "torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_loader = load_data()\n",
    "    verify_model(train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
